ophone audio
- Provide chat‑style UI
- Display answers with sources
- Stream partial responses

**Tech Stack:**
- React
- Web Audio API
- Fetch / WebSocket

**Key UI Components:**
- Voice input button
- Chat history panel
- Source citation panel
- Confidence indicator

---

### 5.2 Backend Application

**Framework:** FastAPI (async)

**Responsibilities:**
- Handle API requests
- Route queries
- Manage ML pipelines
- Serve streaming responses

**Core Endpoints:**
- `/ingest` – document upload
- `
rchitecture

```
User (Browser)
   │
   │ Voice / Text
   ▼
Frontend (React)
   │
   ▼
FastAPI Backend (Async)
   ├── STT Service (Whisper)
   ├── RAG Service
   │    ├── Embedding Model
   │    ├── FAISS Vector Store
   │    └── Retriever
   ├── LLM Inference Service
   └── Monitoring & Metrics
```

---

## 5. Application Modules

### 5.1 Frontend Application

**Responsibilities:**
- Capture microphone audio
- Provide chat‑style UI
- Display answers with sources
- Stream partial responses

**Te
 source grounding**
- Run fully on **local hardware** (RTX 3050, 4 GB VRAM)
- Follow **production ML best practices** (pipelines, versioning, monitoring)
- Be cloud‑ready by design (Vertex AI / GKE compatible)

---

## 3. Target System Specifications

- **RAM:** 16 GB
- **GPU:** NVIDIA RTX 3050 (4 GB VRAM)
- **OS:** Linux / Windows
- **Inference:** Quantized models (4‑bit)

---

## 4. High‑Level Architecture

```
User (Browser)
   │
   │ Voice / Text
   ▼
Frontend (React)
   │
   ▼
FastAPI Backe
**
- **Retrieval Augmented Generation (RAG)**
- **Generative AI**
- **MLOps & monitoring**
- **Scalable backend architecture**

OMKA is designed to reflect **Google‑style AI/ML engineering standards**, focusing on reliability, grounding, modularity, and scalability.

---

## 2. Key Objectives

- Enable **voice‑based and text‑based Q&A** over user documents
- Prevent hallucinations using **RAG with source grounding**
- Run fully on **local hardware** (RTX 3050, 4 GB VRAM)
- Follow **production ML
## 10. Scalability & System Design

Although local, OMKA is built for scale:

- Stateless API design
- Separable inference services
- Batch embedding jobs
- Horizontal scaling ready

**Cloud Migration Path:**
- FAISS → Vertex Matching Engine
- Local LLM → Vertex AI endpoints
- FastAPI → GKE

---

## 11. Security & Privacy

- Fully offline processing
- No external API calls
- Local data storage
- No telemetry leakage

---

## 12. Repository Structure

```
omka/
├── backend/
│   ├── api/
│   ├── r
